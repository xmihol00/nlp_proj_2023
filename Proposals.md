# Privacy-Preservation on Text
* **Large text**: Use of multiple data sets.
* **Pipelines**:
    1. ML: Data sets download, cleaning, pre-processing, training, evaluation, visualisation of results.
    2. Inference: Own document upload, pre-processing, inference on a trained ML model, presentation of results.
* **Pre-processing**: Conversion of all the data sets to the same schema, e.i. consistent word separation and labeling.
* **Analysis**: Summarization of how our solution performs via graphs or tables, clustering of test documents based on types of private information.
* **Interactive output analysis**: GUI for document uploads, which enable the user to further add pseudonyms or remove the detected by the inference pipeline.
